<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Jingdao Chen</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<meta name="author" content="" />

  <!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!--link rel="shortcut icon" href="favicon.ico"-->

	<link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">
	<link rel="stylesheet" href="fontawesome-free-5.13.0-web/css/all.min.css">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Flaticons  -->
	<!--link rel="stylesheet" href="fonts/flaticon/font/flaticon.css"-->
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	<style>
		ol.publication-list li {
			padding-bottom: 15px;
			padding-left: 20px;
		}
		ol.publication-list strong {
			color: #2C90DE;
		}
        #gifdiv img.gifimg {
            border-radius: 10%;
            width: auto;
            height: 30%;
			max-width: 100%;
            padding: 5px;
        }
		.youtube-container {
			text-align: center;
			vertical-align: middle;
		}
		.youtube-image {
		  opacity: 1;
		  transition: .5s ease;
		  backface-visibility: hidden;
		  max-width:100%;
		}
		.youtube-middle {
		  transition: .5s ease;
		  opacity: 0;
		  position: absolute;
		  top: 50%;
		  left: 50%;
		  transform: translate(-50%, -50%);
		  -ms-transform: translate(-50%, -50%);
		  text-align: center;
		}
		.youtube-container:hover .youtube-image {
		  opacity: 0.3;
		  border-radius: 10%;
		}
		.youtube-container:hover .youtube-middle {
		  opacity: 1;
		}
		.paperlink:hover {
			text-decoration: underline;
			cursor: pointer;
		}
		.bibref {
		  margin-top: 10px;
		  margin-left: 10px;
		  display:none;
		  font-size:14px;
		  font-family: monospace;
		}
		.gallery {
		  max-width:100%;
          padding-bottom: 15px;
		}
	</style>

	</head>
	<body>
	<div id="colorlib-page">
		<div class="container-wrap">
		<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><i></i></a>
		<aside id="colorlib-aside" role="complementary" class="border js-fullheight">
			<div class="text-center">
				<div class="author-img" style="background-image: url(images/profile.jpg);"></div>
				<h1 id="colorlib-logo"><a href="index.html">Jingdao Chen</a></h1>
				<span class="position"><a href="#">Mississippi State University</span>
			</div>
			<nav id="colorlib-main-menu" role="navigation" class="navbar">
				<div id="navbar" class="collapse" style="margin-bottom:10px">
					<ul>
						<li class="active"><a href="#" data-nav-section="home">Home</a></li>
						<li><a href="#" data-nav-section="news">News</a></li>
						<li><a href="#" data-nav-section="research">Research</a></li>
						<li><a href="#" data-nav-section="publications">Publications</a></li>
						<li><a href="#" data-nav-section="teaching">Teaching</a></li>
						<li><a href="#" data-nav-section="join">Join</a></li>
						<li><a href="#" data-nav-section="code">Code</a></li>
						<li><a href="#" data-nav-section="gallery">Gallery</a></li>
						<li><a class='external' target="_blank" href="CV.pdf">CV</a></li>
					</ul>
			<div style="text-align:center; font-size:15px;">
					<i class="fa fa-fw fa-map-marker" aria-hidden="true"></i>Starkville, MS<br>
					<a class='external' target="_blank" href="mailto:chenjingdao@cse.msstate.edu" style="color:rgba(0,0,0,0.7)"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a><br>
					<a class='external' target="_blank" href="https://www.researchgate.net/profile/Jingdao_Chen" style="color:rgba(0,0,0,0.7)"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a><br>
					<a class='external' target="_blank" href="https://www.linkedin.com/in/jingdao-chen-82360373/" style="color:rgba(0,0,0,0.7)"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a><br>
					<a class='external' target="_blank" href="https://scholar.google.com/citations?user=ndx5aOcAAAAJ&amp;hl=en&amp;oi=ao" style="color:rgba(0,0,0,0.7)"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a>
			</div>
			<div class="colorlib-footer">
				<p><small>&copy; <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
                <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --> </span>
                <!--span>Demo Images: <a href="https://unsplash.com/" target="_blank">Unsplash.com</a></span-->
                </small></p>
			</div>
				</div>
			</nav>


		</aside>

		<div id="colorlib-main">
			<section id="colorlib-hero" data-section="home">
				<div class="flexslider">
					<ul class="slides">
				   	<li style="background-image: url(images/MSU-Background.jpg);">
				   		<div class="overlay"></div>
				   		<div class="container-fluid">
				   			<div class="row">
					   			<div class="col-md-6 col-sm-12 col-xs-12 js-fullheight slider-text">
					   				<div class="slider-text-inner js-fullheight">
					   					<div class="desc">
						   					<h1>Hi! <br>I'm Jingdao</h1>
						   					<h2>
                                            I am an Assistant Professor at Mississippi State University specializing in robotics, computer vision, and artificial intelligence.
                                            My research areas include construction robotics, disaster relief robotics, digital twins and Scan-to-BIM.
                                            My research uses self-supervised learning, class-agnostic segmentation, and incremental scene understanding
                                            techniques to achieve robust, accurate, real-time perception for intelligent, autonomous agents that operate around the built environment.
                                            I obtained my Bachelors degree at Washington University in St. Louis and my MS and PhD at Georgia Tech.
											</h2>
											</div>
					   				</div>
					   			</div>
					   			<div id="gifdiv" class="col-md-6 col-sm-12 col-xs-12 js-fullheight slider-text">
									<!--a target="_blank" href="https://youtu.be/ihrR7R81m94">
										<img class="gifimg" src="images/kitti.gif" >
									</a-->
									<a target="_blank" href="https://youtu.be/JIOWMo4wfSo">
										<img  class="gifimg" src="images/excavator.gif">
									</a>
									<a target="_blank" href="https://youtu.be/S-Irf5B9l4w">
										<img class="gifimg" src="images/guardian.gif" >
									</a>
									<a target="_blank" href="https://youtu.be/VeaENwp6CnM">
										<img class="gifimg" src="images/incremental.gif" >
									</a>
									<!--a target="_blank" href="https://youtu.be/8dwVW_4CrgY">
										<img  class="gifimg" src="images/nuclear.gif">
									</a-->
                                </div>
					   		</div>
				   		</div>
				   	</li>
				  	</ul>
			  	</div>
			</section>

			<section class="colorlib-experience" data-section="news">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 " data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading ">News</h2>
						</div>
					</div>
                    <ul>
                        <li> 05/2024: <b>[Workshop]</b> on <a target="_blank" href="https://construction-robots.github.io/index.html">construction robotics</a> at ICRA 2025 in Atlanta</li> 					 	
                        <li> 05/2021: <code>[Paper]</code> accepted at Robotics and Automation Magazine</li> 					 	
                        <li> 09/2024: <code>[Funding]</code> from <a target="_blank" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2342574">NSF ITEST</a>, press release <a target="_blank" href="https://www.msstate.edu/newsroom/article/2024/11/msu-receives-12-million-nsf-grant-promote-ai-competency-among-high-school">here</a></li>
                        <li> 07/2024: <b>[Workshop]</b> on <a target="_blank" href="https://github.com/jingdao/i3ce2024_DL_Workshop">deep learning for the built environment</a> at I3CE 2024 in Pittsburgh</li> 					 	
                        <li> 05/2024: Established new IEEE RAS Technical Committee on <a target="_blank" href="https://www.ieee-ras.org/construction-robotics">Construction Robotics</a></li>
                        <li> 05/2024: <b>[Workshop]</b> on <a target="_blank" href="https://construction-robots.github.io/index2024.html">construction robotics</a> at ICRA 2024 in Yokohama</li> 					 	
                        <li> 09/2023: <code>[Funding]</code> from <a target="_blank" href="https://www.nasa.gov/learning-resources/established-program-to-stimulate-competitive-research/awards/">NASA EPSCoR R3</a></li>
                        <li> 07/2023: <code>[Funding]</code> from <a target="_blank" href="https://www.iarpa.gov/research-programs/wriva">IARPA WRIVA</a></li>
                        <li> 06/2023: <code>[Funding]</code> from <a target="_blank" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2246920&HistoricalAwards=false">NSF SaTC</a></li>
                        <li> 06/2023: <b>[Workshop]</b> on <a target="_blank" href="https://construction-robots.github.io/index2023.html">construction robotics</a> at ICRA 2023 in London</li> 					 	
                        <li> 01/2023: 2 <code>[papers]</code> accepted at SPIE Defense + Commercial Sensing
                        <li> 10/2022: 2 <code>[papers]</code> accepted at ECCV AI4Space workshop
                        <li> 06/2022: <b>[Workshop]</b> on <a target="_blank" href="https://github.com/jingdao/Scan-to-BIM-Workshop">Scan-to-BIM</a> at ICCEPM</li>
                        <li> 06/2022: <b>[Session Chair]</b> at ICCEPM</li>
                        <li> 05/2022: <code>[Funding]</code> from <a target="_blank" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2153101&HistoricalAwards=false">NSF CRII</a></li>
                        <li> 05/2022: <b>[Workshop]</b> on <a target="_blank" href="https://construction-robots.github.io/index2022.html">construction robotics</a> at ICRA 2022 in Philadelphia</li> 					 	
                        <li> 04/2022: <code>[Paper]</code> accepted at Advanced Engineering Informatics </li> 					 	
                        <li> 04/2022: <b>[Invited talk]</b> at IEEE Mississippi
                        <li> 05/2022: <code>[Book Chapter]</code> on Building Information Modeling </li> 					 	
                        <li> 09/2021: <b>[Session Chair]</b> at I3CE</li>
                        <li> 06/2021: <b>[Presentation]</b> at CVPR Workshop on Computer Vision in the Built Environment
                        <li> 05/2021: <code>[Paper]</code> accepted at IEEE RA-L + presented at ICRA</li> 					 	
                        <li> 04/2021: <code>[Paper]</code> accepted at Automation in Construction</li> 					 	
                        <li> 06/2020: <code>[Paper]</code> accepted at Automation in Construction</li> 					 	
                    </ul>
                </div>
            </section>

			<section class="colorlib-experience" data-section="research">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 animate-box" data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading animate-box">Research</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12">
				         <div class="timeline-centered">

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>
					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
											<h2>3D Point Cloud Modeling</h2>
											  <p>
												  Emerging technological advances in photogrammetry and LiDAR sensing allow point cloud data to be collected on a large-scale basis,
												  yet interpreting the raw data and rendering it into formats that are useful for end users remains a fundamental research challenge.
												  Especially, point cloud data is largely unstructured and comes with many imperfections such as sensor artifacts, occlusion, and clutter in the environment.
												  My research work in the field of point cloud scene understanding includes 3D descriptors, multi-view segmentation, incremental segmentation, transferable point feature embeddings and learnable region growing.
											  </p>
											  <p> Relevant papers:
												<a class="paperlink" target="_blank" href="https://doi.org/10.1109/LRA.2021.3062607">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1109/LRA.2019.2894915">[2]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000842">[3]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1016/j.autcon.2017.10.033">[4]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000628">[5]</a>
											  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12 row-pt-md">
											<a target="_blank" href="https://youtu.be/qj7XcgAGXOc">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/qj7XcgAGXOc/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12 row-pt-md">
											<a target="_blank" href="https://youtu.be/VeaENwp6CnM">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/VeaENwp6CnM/mqdefault.jpg" class="youtube-image">
											</div>
											</a>
                                            <br><br>
											<a target="_blank" href="https://youtu.be/ihrR7R81m94">
												<img src="images/kitti.gif" class="gifimg">
                                            </a>
										</div>
					               </div>
					            </div>
					         </article>

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInRight">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>
					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
											<h2>Scan-to-BIM Digital Twin Reconstruction</h2>
											  	<p>
												  Scan-to-BIM commonly refers to the process of converting raw, unorganized laser-scanned point cloud data into 
												  interpretable, semantically-rich Building Information Models (BIM) that are easily accessible to engineers and site managers.
												  The obtained building model can be used for construction progress monitoring, asset management, deviation detection, safety analysis, and restoration of historical buildings.
												  My research investigates machine learning techniques for Scan-to-BIM including 
												  point cloud instance segmentation, CAD model matching and representation learning for building element retrieval.
												</p>
											  <p> Relevant papers:
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000842">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1016/j.autcon.2020.103159">[2]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/9780784482865.139">[3]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/9780784481264.022">[4]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1680/icsic.64669.225">[5]</a>
											  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12">
											<a target="_blank" href="https://youtu.be/BEfZ5qTfSDo">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/BEfZ5qTfSDo/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12 row-pt-md">
											<a target="_blank" href="https://youtu.be/zuPE9aB_wkE">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/zuPE9aB_wkE/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
					               </div>
					            </div>
					         </article>

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>
					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
										  <h2>Construction Robotics</h2>
										  <p>When automating the operation of heavy construction equipment such as excavators and cranes, accurate spatial information
											  about the surrounding environment is needed to carry out manipulation tasks accurately and efficiently. My research investigates
											  sensor-driven 3D workspace models that can be continuously updated to provide feedback concerning the progress of manipulation tasks.
											  This work includes a workspace visualization and pose estimation framework for teleoperated excavators and
											  a crane operation assistance system incorporating collision warning, load swing tracking, and moving hazard detection.
										  </p>
										  <p>Relevant papers: 
												<a class="paperlink" target="_blank" href="https://doi.org/10.22260/ISARC2020/0108">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1080/24705314.2018.1531348">[2]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000698">[3]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000628">[4]</a>
										  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12" >
											<a target="_blank" href="https://youtu.be/JIOWMo4wfSo">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/JIOWMo4wfSo/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12 row-pt-md">
											<a target="_blank" href="https://youtu.be/vn8qw0WVqn8">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/vn8qw0WVqn8/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
					               </div>
								  </div>
					         </article>

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInRight">
					            <div class="timeline-entry-inner">

					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>

					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
										  <h2>Disaster Relief / Radiation Mapping Robotics</h2>
										  <p>
                                        Disaster relief and response plays an important role in saving lives and reducing economic loss after earthquakes, windstorm events and man-made explosions.
                                        Mobile robots represent an effective solution to assist in post-disaster reconnaissance in areas that are dangerous to human agents due to chemical or radiation leaks.
                                        <!--These robots need an accurate 3D semantic map of the site in order to carry out disaster relief work such as search and rescue and damage assessment.-->
                                        <!--There exists a research need to automatically identify building elements and detect structural damage from laser-scanned points clouds acquired by mobile robots.-->
                                        My research work in this domain includes simulation of nuclear power plant disaster sites, point cloud segmentation of damaged building elements,
										anomaly-based crack segmentation of post-earthquake structures, and radiation mapping of nuclear facilities.
										  </p>
										  <p>Relevant papers: 
												<a class="paperlink" target="_blank" href="https://smartech.gatech.edu/handle/1853/64717">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1016/j.aei.2022.101550">[2]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.22260/ISARC2021/0048">[3]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1109/URAI.2019.8768770">[4]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/9780784482421.069">[5]</a>
										  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12" >
											<a target="_blank" href="https://youtu.be/S-Irf5B9l4w">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/S-Irf5B9l4w/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12" >
											<a target="_blank" href="https://youtu.be/NOwD53v2EW8">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/NOwD53v2EW8/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div>
										<!--div class="col-md-5 col-sm-12 col-xs-12 row-pt-md">
											<a target="_blank" href="https://youtu.be/8dwVW_4CrgY">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/8dwVW_4CrgY/mqdefault.jpg" class="youtube-image">
												<div class="youtube-middle">
												  <i class="icon-media-play" style="font-size:60px;color:#303030"></i>
												</div>
											</div>
											</a>
										</div-->
										<!--div class="col-md-5 col-sm-12 col-xs-12 row-pt-md" >
                                            <img src="images/dubot.jpg" class="youtube-image">
										</div-->
					               </div>
								  </div>
					         </article>

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>
					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
										  <h2>Off-road Robotics</h2>
										  <p>
                                          Off-road environments such as those found in construction, agriculture, forestry, mining, and rural transportation offer a significant challenge for autonomous driving due to the unstructured and unpredictable hazards in the form of uneven terrain in addition to varied vegetation and rocks.
                                          In on-road environments, it is straightforward to navigate based on cues from traffic signs and lane markings.
                                          Whereas, in off-road environments, navigation algorithms have to perform higher-level scene understanding and consider complex terrain interactions as well as the relative hazards of different obstacles in the environment.
                                          My research work in this domain include self-supervised traversability estimation, uncertainty-aware planning, and digital twin modeling for off-road environments.
										  </p>
										  <p>Relevant papers: 
												<a class="paperlink" target="_blank" href="https://doi.org/10.1117/12.2663632">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1117/12.2663098">[2]</a>
										  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12" >
                                            <img src="images/off-road.jpg" class="youtube-image">
                                            <img src="images/backyard.jpg" class="youtube-image">
                                            <!--img src="images/backyard2.jpg" class="youtube-image"-->
                                            <br><br>
											<a target="_blank" href="https://youtu.be/L0weyjXJRf0">
											<div class="youtube-container">
												<img src="https://img.youtube.com/vi/L0weyjXJRf0/mqdefault.jpg" class="youtube-image">
											</div>
											</a>
										</div>
					               </div>
								  </div>
					         </article>

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>
					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
										  <h2>Perception for Planetary Rovers</h2>
										  <p>
                                          Planetary rovers represent one of the primary means by which humans are able to explore and understand other celestial bodies, as exemplified by the Mars 2020 rover mission and the Lunar 2023 VIPER mission.
                                          However, Mars surface images suffer from a lack of expert-labeled training data and domain shift in image features as the rover moves to different sites on a planet.
                                          In addition, due to power constraints and extensive flight qualification requirements (e.g., radiation tolerance), current space-qualified hardware still mostly relies on legacy technologies.
                                          To address these issues, this research investigates techniques such as contrastive learning, knowledge distillation, and mixed-domain training to provide more accurate and efficient perception models for planetary rovers.
										  </p>
										  <p>Relevant papers: 
												<a class="paperlink" target="_blank" href="https://doi.org/10.1007/978-3-031-25056-9_12">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1007/978-3-031-25056-9_7">[2]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1109/AERO53065.2022.9843245">[3]</a>
										  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12" >
                                            <img src="images/mars.jpg" class="youtube-image">
										</div>
					               </div>
								  </div>
					         </article>

					         <article class="timeline-entry animate-box" data-animate-effect="fadeInLeft">
					            <div class="timeline-entry-inner">
					               <div class="timeline-icon color-1">
					                  <i class="icon-folder"></i>
					               </div>
					               <div class="timeline-label">
										<div class="col-md-7 col-sm-12 col-xs-12">
										  <h2>Remote Monitoring with UAVs</h2>
										  <p>
                                          Highway infrastructure maintenance and monitoring tasks often involve labor-intensive activities and long inspection times.
                                          Examples of these maintenance tasks include landscaping and lawn care, detecting damaged road segments, and identifying missing road signs.
                                          To efficiently automate the maintenance inspection tasks, my research proposes an automated monitoring framework using Unmanned Aerial Vehicles (UAV).
                                          Structure from Motion (SfM) is used to create dense 3D point clouds from image data and deep learning techniques are used to segment and classify different highway assets.
                                          Point cloud-based temporal change detection is carried out with a focus on grass height estimation for monitoring highway mowing operations.
										  </p>
										  <p>Relevant papers: 
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/9780784483893.110">[1]</a>
												<a class="paperlink" target="_blank" href="https://doi.org/10.1061/9780784483893.109">[2]</a>
										  </p>
										</div>
										<div class="col-md-5 col-sm-12 col-xs-12" >
                                            <img src="images/sfm.jpg" class="youtube-image">
										</div>
					               </div>
								  </div>
					         </article>

						</div>
						</div>
					</div>
				</div>
			</section>

			<section data-section="publications">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 " data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading ">Publications</h2>
						</div>
					</div>
					<div class="row">
						<div class="col-md-12 " data-animate-effect="fadeInLeft">
							<div class="fancy-collapse-panel">
								<div class="panel-group" id="accordion" role="tablist" aria-multiselectable="true">
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingOne">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" href="#collapseOne" aria-expanded="false" aria-controls="collapseOne"> Journal Publications
									            </a>
									        </h4>
									    </div>
									    <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
									         <div class="panel-body">
												<ol class='publication-list'>
	<h3>2024</h3>
	<li>
	Armeni, I., <b>Chen, J.</b>, Feng, C., Jeong, I., Liang, C.J., Morin, K., Tsagarakis, N., Wang, X., and Zhang, L. (2024). <br>
	<a target="_blank" href="https://doi.org/10.1109/MRA.2024.3481769"><strong>Construction Robotics and Automation [TC Spot Light]</strong></a><br>
	IEEE Robotics and Automation Magazine, vol. 31, no. 4, pp. 186-192, Dec. 2024<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @ARTICLE{armeni2024,<br>
            author={Armeni, Iro and Chen, Jingdao and Feng, Chen and Jeong, Inbae and Liang, Ci-Jyun and Morin, Kristian and Tsagarakis, Nikos and Wang, Xi and Zhang, Liangjun},<br>
            journal={IEEE Robotics and Automation Magazine}, <br>
            title={Construction Robotics and Automation [TC Spot Light]}, <br>
            year={2024},<br>
            volume={31},<br>
            number={4},<br>
            pages={186-192},<br>
            doi={10.1109/MRA.2024.3481769},<br>
        }
		</div>
	</li>
	<li>
	Neupane, S., Mitra, S., Fernandez, I., Saha, S., Mittal, S., <b>Chen, J.</b>, Pillai, S., and Rahimi, S. (2024). <br>
	<a target="_blank" href="https://doi.org/10.1109/ACCESS.2024.3363657"><strong>Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities</strong></a><br>
	IEEE Access, vol. 12, pp. 22072-22097<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @ARTICLE{neupane2024,<br>
            author={Neupane, Subash and Mitra, Shaswata and Fernandez, Ivan A. and Saha, Swayamjit and Mittal, Sudip and Chen, Jingdao and Pillai, Nisha and Rahimi, Shahram},<br>
            journal={IEEE Access},<br>
            title={Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities},<br>
            year={2024},<br>
            volume={12},<br>
            number={},<br>
            pages={22072-22097},<br>
            doi={10.1109/ACCESS.2024.3363657},<br>
        }
		</div>
	</li>
    <li>
	Gao, K., Haverly, A., Mittal, S., Wu, J., and <b>Chen, J.</b> (2024). <br>
	<a target="_blank" href="https://doi.org/10.4018/IJBAN.338367"><strong>AI Ethics: A Bibliometric Analysis, Critical Issues, and Key Gaps</strong></a><br>
	International Journal of Business Analytics (IJBAN), 11(1), 1-19 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @ARTICLE{gao2024,<br>
            author={Gao, Kevin Di and Haverly, Andrew and Mittal, Sudip and Wu, Jiming and Chen, Jingdao},<br>
            journal={International Journal of Business Analytics},<br>
            title={AI Ethics: A Bibliometric Analysis, Critical Issues, and Key Gaps},<br>
            year={2024},<br>
            volume={11},<br>
            number={1},<br>
            pages={19},<br>
        }
		</div>
	</li>
	<h3>2023</h3>
	<li>
	Vincent, G., Ward, I., Moore, C., <b>Chen, J.</b>, Pak, K., Yepremyan, A., Wilson, B., and Goh, E. (2023). <br>
	<a target="_blank" href="https://doi.org/10.2514/1.A35767"><strong>CLOVER: Contrastive Learning for Onboard Vision-Enabled Robotics</strong></a><br>
	Journal of Spacecraft and Rockets, 61:3, 728-740 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @article{vincent2023,<br>
            author = {Vincent, Grace M. and Ward, Isaac R. and Moore, Charles and Chen, Jingdao and Pak, Kai and Yepremyan, Alice and Wilson, Brian and Goh, Edwin Y.},<br>
            title = {CLOVER: Contrastive Learning for Onboard Vision-Enabled Robotics},<br>
            journal = {Journal of Spacecraft and Rockets},<br>
            volume = {61},<br>
            number = {3},<br>
            pages = {728-740},<br>
            year = {2024},<br>
            doi = {10.2514/1.A35767},<br>
        }
		</div>
	</li>
	<h3>2022</h3>
	<li>
	<b>Chen, J.</b>, and Cho, Y. (2022). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.aei.2022.101550"><strong>CrackEmbed: Point feature embedding for crack segmentation from disaster site point clouds with anomaly detection</strong></a><br>
	Advanced Engineering Informatics, Volume 52, April 2022<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{chen2022aei,<br>
			title = {CrackEmbed: Point feature embedding for crack segmentation from disaster site point clouds with anomaly detection},<br>
			journal = {Advanced Engineering Informatics},<br>
			volume = {52},<br>
			pages = {101550},<br>
			year = {2022},<br>
			issn = {1474-0346},<br>
			doi = {https://doi.org/10.1016/j.aei.2022.101550},<br>
			url = {https://www.sciencedirect.com/science/article/pii/S1474034622000258},<br>
			author = {Jingdao Chen and Yong Kwon Cho},<br>
		}
		</div>
	</li>
	<h3>2021</h3>
    <li>
	<b>Chen, J.</b>, Kira, Z. and Cho, Y. (2021). <br>
	<a target="_blank" href="https://doi.org/10.1109/LRA.2021.3062607"><strong>LRGNet: Learnable Region Growing for Class-Agnostic Point Cloud Segmentation</strong></a><br>
	IEEE Robotics and Automation Letters, 6(2), pp. 2799-2806. Accepted for oral presentation at the International Conference on Robotics and Automation (ICRA) 2021. <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/learn_region_grow">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@ARTICLE{chen2021ral,<br>
        title={LRGNet: Learnable Region Growing for Class-Agnostic Point Cloud Segmentation},<br>
		author={J. {Chen} and Z. {Kira} and Y. K. {Cho}},<br>
		journal={IEEE Robotics and Automation Letters},<br>
        year = {2021},<br>
        volume={6},<br>
        number={2},<br>
        pages={2799-2806},<br>
		}
		</div>
	</li>
	<li>Price, L., <b>Chen, J.</b>, Park, J. and Cho Y. (2021). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.autcon.2021.103552"><strong>Multisensor-driven real-time crane monitoring system for blind lift operations: Lessons learned from a case study</strong></a> <br>
	Automation in Construction, Volume 124, April 2021 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{price2021autcon,<br>
        title = {Multisensor-driven real-time crane monitoring system for blind lift operations: Lessons learned from a case study},<br>
        journal = {Automation in Construction},<br>
        volume = {124},<br>
        pages = {103552},<br>
        year = {2021},<br>
        issn = {0926-5805},<br>
        doi = {https://doi.org/10.1016/j.autcon.2021.103552},<br>
        url = {https://www.sciencedirect.com/science/article/pii/S0926580521000030},<br>
        author = {Leon C. Price and Jingdao Chen and Jisoo Park and Yong K. Cho},<br>
		}
		</div>
	</li>
    <h3>2020</h3>
    <li><b>Chen, J.</b>, Yi, J., Kahoush, M., Cho, E. and Cho, Y. (2020). <br>
    <a target="_blank" href="https://doi.org/10.3390/s20185029"><strong>Point Cloud Scene Completion of Obstructed Building Facades with Generative Adversarial Inpainting</strong></a><br>
    MDPI Sensors, 20(18), 5029 <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/point_cloud_scene_completion">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @Article{chen2020sensors,<br>
        AUTHOR = {Chen, Jingdao and Yi, John Seon Keun and Kahoush, Mark and Cho, Erin S. and Cho, Yong K.},<br>
        TITLE = {Point Cloud Scene Completion of Obstructed Building Facades with Generative Adversarial Inpainting},<br>
        JOURNAL = {Sensors},<br>
        VOLUME = {20},<br>
        YEAR = {2020},<br>
        NUMBER = {18},<br>
        ARTICLE-NUMBER = {5029},<br>
        URL = {https://www.mdpi.com/1424-8220/20/18/5029},<br>
        ISSN = {1424-8220},<br>
        DOI = {10.3390/s20185029}<br>
        }
        </div>
    </li>
	<li>Zeng, S., <b>Chen, J.</b>, and Cho Y. (2020). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.autcon.2020.103159"><strong>User Exemplar-based Building Element Retrieval from Raw Point Clouds using Deep Point-level Features</strong></a> <br>
	Automation in Construction, Volume 114, June 2020, 103159 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{zeng2020autcon,<br>
		title = "User exemplar-based building element retrieval from raw point clouds using deep point-level features",<br>
		journal = "Automation in Construction",<br>
		volume = "114",<br>
		pages = "103159",<br>
		year = "2020",<br>
		issn = "0926-5805",<br>
		doi = "https://doi.org/10.1016/j.autcon.2020.103159",<br>
		url = "http://www.sciencedirect.com/science/article/pii/S0926580519310908",<br>
		author = "Shiqin Zeng and Jingdao Chen and Yong K. Cho",<br>
		}
		</div>
	</li>
	<li>Park, J.S., <b>Chen, J.</b>, Cho, Y., Kang, D., and Son, B. (2020).<br>
	<a target="_blank" href="https://doi.org/10.3390/s20010034"><strong>CNN-Based Person Detection Using Infrared Images for Night-Time Intrusion Warning System.</strong></a><br>
	MDPI Sensors, 20(1), 34 <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/IR_detection">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{park2020sensors,<br>
		AUTHOR = {Park, Jisoo and Chen, Jingdao and Cho, Yong K. and Kang, Dae Y. and Son, Byung J.},<br>
		TITLE = {CNN-Based Person Detection Using Infrared Images for Night-Time Intrusion Warning Systems},<br>
		JOURNAL = {Sensors},<br>
		VOLUME = {20},<br>
		YEAR = {2020},<br>
		NUMBER = {1},<br>
		ARTICLE-NUMBER = {34},<br>
		URL = {https://www.mdpi.com/1424-8220/20/1/34},<br>
		ISSN = {1424-8220},<br>
		DOI = {10.3390/s20010034},<br>
		}
		</div>
	</li> 
    <h3>2019</h3>
    <li>
	<b>Chen, J.</b>, Cho, Y., and Kira, Z. (2019). <br>
	<a target="_blank" href="https://doi.org/10.1109/LRA.2019.2894915"><strong>Multi-view Incremental Segmentation of 3D Point Clouds for Mobile Robots.</strong></a><br>
	IEEE Robotics and Automation Letters, 4(2), pp. 1240-1246,10.1109/LRA.2019.2894915 <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/multiview_segmentation">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@ARTICLE{chen2019ral,<br>
		author={J. {Chen} and Y. K. {Cho} and Z. {Kira}},<br>
		journal={IEEE Robotics and Automation Letters},<br>
		title={Multi-View Incremental Segmentation of 3-D Point Clouds for Mobile Robots},<br>
		year={2019},<br>
		volume={4},<br>
		number={2},<br>
		pages={1240-1246},<br>
		}
		</div>
	</li> <li>
	<b>Chen, J.</b>, Kira, Z., and Cho, Y. (2019). <br>
	<a target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000842"><strong>Deep Learning Approach to Point Cloud Scene Understanding for Automated Scan to 3D Reconstruction.</strong></a><br>
	ASCE Journal of Computing in Civil Engineering, 33(4) DOI:10.1061/(ASCE)CP.1943-5487.0000842 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{chen2019jcce,<br>
		author = {Jingdao Chen  and Zsolt Kira  and Yong K. Cho },<br>
		title = {Deep Learning Approach to Point Cloud Scene Understanding for Automated Scan to 3D Reconstruction},<br>
		journal = {Journal of Computing in Civil Engineering},<br>
		volume = {33},<br>
		number = {4},<br>
		pages = {04019027},<br>
		year = {2019},<br>
		doi = {10.1061/(ASCE)CP.1943-5487.0000842},<br>
		}
		</div>
	</li>
    <h3>2018</h3>
    <li>
	Fang, Y., <b>Chen, J.</b>, Cho, Y., and Kim, K.N. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1080/24705314.2018.1531348"><strong>Vision-based Load Sway Monitoring to Improve Crane Safety in Blind Lifts. </strong></a><br>
	Journal of Structural Integrity and Maintenance, 10.1080/24705314.2018.1531348 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{fang2018jsim,<br>
		author = {Yihai Fang and Jingdao Chen and Yong K. Cho and Kinam Kim and Sijie Zhang and Esau Perez},<br>
		title = {Vision-based load sway monitoring to improve crane safety in blind lifts},<br>
		journal = {Journal of Structural Integrity and Maintenance},<br>
		volume = {3},<br>
		number = {4},<br>
		pages = {233-242},<br>
		year  = {2018},<br>
		publisher = {Taylor &amp; Francis},<br>
		doi = {10.1080/24705314.2018.1531348},<br>
		}
		</div>
	</li> <li>
	Kim, P., <b>Chen, J.</b>, and Cho, Y. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.autcon.2018.01.009"><strong> SLAM-driven robotic mapping and registration of 3D point clouds.</strong></a><br>
	Automation in Construction, doi.org/10.1016/j.autcon.2018.01.009 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{kim2018autcon,<br>
		title = "SLAM-driven robotic mapping and registration of 3D point clouds",<br>
		journal = "Automation in Construction",<br>
		volume = "89",<br>
		pages = "38 - 48",<br>
		year = "2018",<br>
		issn = "0926-5805",<br>
		doi = "https://doi.org/10.1016/j.autcon.2018.01.009",<br>
		url = "http://www.sciencedirect.com/science/article/pii/S0926580517303990",<br>
		author = "Pileun Kim and Jingdao Chen and Yong K. Cho",<br>
		}
		</div>
	</li> <li>
	<b>Chen, J.</b>, Fang, Y., and Cho, Y. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.autcon.2017.10.033"><strong> Performance Evaluation of 3D Descriptors for Object Recognition in Construction Applications.</strong></a><br>
	Automation in Construction, Volume 86,February 2018, Pages 44-52, DOI: 10.1016/j.autcon.2017.10.033 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{chen2018autcon,<br>
		title = "Performance evaluation of 3D descriptors for object recognition in construction applications",<br>
		journal = "Automation in Construction",<br>
		volume = "86",<br>
		pages = "44 - 52",<br>
		year = "2018",<br>
		issn = "0926-5805",<br>
		doi = "https://doi.org/10.1016/j.autcon.2017.10.033",<br>
		url = "http://www.sciencedirect.com/science/article/pii/S0926580517303862",<br>
		author = "Jingdao Chen and Yihai Fang and Yong K. Cho",<br>
		}
		</div>
	</li> <li>
	Kim, P., <b>Chen, J.</b>, and Cho, Y. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000720%20"><strong> Automated Point Clouds Registration using Visual and Planar Features for Construction Environments.</strong></a><br>
	ASCE Journal of Computing in Civil Engineering, Volume 32, Issue2, March 2018, DOI: 10.1061/(ASCE)CP.1943-5487.0000720 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{kim2018jcce,<br>
		author = {Pileun Kim  and Jingdao Chen  and Yong K. Cho },<br>
		title = {Automated Point Cloud Registration Using Visual and Planar Features for Construction Environments},<br>
		journal = {Journal of Computing in Civil Engineering},<br>
		volume = {32},<br>
		number = {2},<br>
		pages = {04017076},<br>
		year = {2018},<br>
		doi = {10.1061/(ASCE)CP.1943-5487.0000720}<br>
		}
		</div>
	</li>
    <h3>2017</h3>
    <li>
	Kim, P., <b>Chen, J.</b>, and Cho, Y. (2017). <br>
	<a target="_blank" href="https://doi.org/10.1007/s41315-017-0023-9"><strong> Robotic sensing and object recognition from thermal-mapped point clouds.</strong></a><br>
	International Journal of Intelligent Robotics and Applications. September 2017, Volume 1, Issue 3, Pages 243-254, DOI: 10.1007/s41315-017-0023-9 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@Article{kim2017ijira,<br>
		author="Kim, Pileun<br>
		and Chen, Jingdao<br>
		and Cho, Yong K.",<br>
		title="Robotic sensing and object recognition from thermal-mapped point clouds",<br>
		journal="International Journal of Intelligent Robotics and Applications",<br>
		year="2017",<br>
		month="Sep",<br>
		day="01",<br>
		volume="1",<br>
		number="3",<br>
		pages="243--254",<br>
		}
		</div>
	</li> <li>
	<b>Chen, J.</b>, Fang, Y., and Cho, Y. (2017). <br>
	<a target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000698"><strong> Real-Time 3D Crane Workspace Update Using a Hybrid Visualization Approach.</strong></a><br>
	ASCE Journal of Computing in Civil Engineering, Volume 31, Issue 5, DOI: 10.1061/(ASCE)CP.1943-5487.0000698 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{chen2017jcce,<br>
		author = {Jingdao Chen  and Yihai Fang  and Yong K. Cho },<br>
		title = {Real-Time 3D Crane Workspace Update Using a Hybrid Visualization Approach},<br>
		journal = {Journal of Computing in Civil Engineering},<br>
		volume = {31},<br>
		number = {5},<br>
		pages = {04017049},<br>
		year = {2017},<br>
		doi = {10.1061/(ASCE)CP.1943-5487.0000698},<br>
		}
		</div>
	</li> <li>
	Park, J.W., <b>Chen, J.</b>, and Cho, Y. (2017). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.aei.2017.02.001"><strong> Self-Corrective Knowledge-based Hybrid Tracking System Using BIM and Multimodal Sensors.</strong></a><br>
	Advanced Engineering Informatics, Volume 32, Issue C, April 2017, Pages 126-138, DOI: 10.1016/j.aei.2017.02.001 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{park2017aei,<br>
		title = "Self-corrective knowledge-based hybrid tracking system using BIM and multimodal sensors",<br>
		journal = "Advanced Engineering Informatics",<br>
		volume = "32",<br>
		pages = "126 - 138",<br>
		year = "2017",<br>
		issn = "1474-0346",<br>
		doi = "https://doi.org/10.1016/j.aei.2017.02.001",<br>
		url = "http://www.sciencedirect.com/science/article/pii/S147403461630252X",<br>
		author = "JeeWoong Park and Jingdao Chen and Yong K. Cho",<br>
		}
		</div>
	</li> <li>
	<b>Chen, J.</b>, Fang, Y., Cho, Y., Kim, C. (2017). <br>
	<a target="_blank" href="https://doi.org/10.1061/(ASCE)CP.1943-5487.0000628"><strong> Principal Axes Descriptor (PAD) for Automated Construction Equipment Classification from Point Clouds.</strong></a><br>
	ASCE's Journal of Computing in Civil Engineering, Volume 31, Issue 2, March 2017, DOI: 10.1061/(ASCE)CP.1943-5487.0000628 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{chen2017pad,<br>
		author = {Jingdao Chen  and Yihai Fang  and Yong K. Cho  and Changwan Kim },<br>
		title = {Principal Axes Descriptor for Automated Construction-Equipment Classification from Point Clouds},<br>
		journal = {Journal of Computing in Civil Engineering},<br>
		volume = {31},<br>
		number = {2},<br>
		pages = {04016058},<br>
		year = {2017},<br>
		doi = {10.1061/(ASCE)CP.1943-5487.0000628}<br>
		}
		</div>
	</li>
    <h3>2016</h3>
    <li>
	Fang, Y.,Cho, Y., and <b>Chen, J.</b> (2016). <br>
	<a target="_blank" href="https://doi.org/10.1016/j.autcon.2016.08.025"><strong> A Framework for Real-time Pro-active Safety Assistance for Mobile Crane Lifting Operations.</strong></a><br>
	Automation in Construction, Volume 72, Part 3, December 2016, Pages 367-379, DOI: 10.1016/j.autocon.2016.08.025 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@article{fang2016autcon,<br>
		title = "A framework for real-time pro-active safety assistance for mobile crane lifting operations",<br>
		journal = "Automation in Construction",<br>
		volume = "72",<br>
		pages = "367 - 379",<br>
		year = "2016",<br>
		issn = "0926-5805",<br>
		doi = "https://doi.org/10.1016/j.autcon.2016.08.025",<br>
		url = "http://www.sciencedirect.com/science/article/pii/S0926580516301807",<br>
		author = "Yihai Fang and Yong K. Cho and Jingdao Chen",<br>
		}
		</div>
	</li>
												</ol>
									         </div>
									    </div>
									</div>
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingTwo">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" target="_blank" href="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo"> Conference Publications
									            </a>
									        </h4>
									    </div>
									    <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
									        <div class="panel-body">
												<ol class='publication-list'>
    <h3>2024</h3>
    <li>
	Fernandez, I., Neupane, S., Chakraborty, T., Mitra, S., Mittal, S., Pillai, N., <b>Chen, J.</b>, and Rahimi, S. (2024). <br>
	<a target="_blank" href="https://conferences.computer.org/cicpub24/#!/toc/0"><strong>A Survey on Privacy Attacks Against Digital Twin Systems in AI-Robotics</strong></a><br>
	 2024 IEEE 10th International Conference on Collaboration and Internet Computing (CIC), Washington, District of Columbia, United States, 28 - 30 October 2024 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		</div>
    </li>
    <li>
	Gao, K., Mittal, S., Wu, J., Du, H., <b>Chen, J.</b>, and Rahimi, S. (2024). <br>
	<a target="_blank" href=""><strong>The AI Pentad, the CHARME2D Model, and an Assessment of Current-State AI Regulation</strong></a><br>
	 10th IEEE International Conference on Sustainable Technology and Engineering (i-COSTE), Perth, Australia, 18th - 20th December, 2024 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		</div>
    </li>
    <li>
	Yu, J., Saha, S., Jayakumar, M., Gugssa, M., <b>Chen, J.</b>, and Wang, J. (2024). <br>
	<a target="_blank" href=""><strong>LiDAR-based Traversability Estimation for Ground Robots on Construction Sites using Self-Supervised Learning</strong></a><br>
	 Proceedings of the ASCE 2024 International Conference on Computing in Civil Engineering (i3CE), Pittsburgh, PA, USA, July 28-31 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		</div>
    </li>
    <li>
	Rugg, J., <b>Chen, J.</b>, Gugssa, M., and Wang, J. (2024). <br>
	<a target="_blank" href=""><strong>Object-level Temporal Change Detection on Construction Sites with 3D Deep Learning Models</strong></a><br>
	 Proceedings of the ASCE 2024 International Conference on Computing in Civil Engineering (i3CE), Pittsburgh, PA, USA, July 28-31 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		</div>
    </li>
    <li>
	Chang, S., <b>Chen, J.</b>, and Park, J. (2024). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784485293.031"><strong>Review of Metaverse Technologies to Broaden Accessibility in Civil and Construction Engineering Education</strong></a><br>
	  ASCE Construction Research Congress (CRC) 2024, March 20-23, Des Moines, IA.<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @inbook{chang2024,<br>
            author = {Soowon Chang  and Jingdao Chen  and Jisoo Park },<br>
            title = {Review of Metaverse Technologies to Broaden Accessibility in Civil and Construction Engineering Education},<br>
            booktitle = {Construction Research Congress 2024},<br>
            chapter = {},<br>
            pages = {304-314},<br>
            doi = {10.1061/9780784485293.031},<br>
            URL = {https://ascelibrary.org/doi/abs/10.1061/9780784485293.031},<br>
        }
		</div>
    </li>
    <h3>2023</h3>
    <li>
	Gao, K., Haverly, A., Mittal, S., and <b>Chen, J.</b> (2023). <br>
	<a target="_blank" href="https://doi.org/10.1109/CSDE59766.2023.10487710"><strong>A bibliometric view of AI Ethics development</strong></a><br>
	 2023 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE), Yanuca Island, Fiji, Dec 4-6,<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @INPROCEEDINGS{gao2023,<br>
            author={Gao, Kevin Di and Haverly, Andrew and Mittal, Sudip and Chen, Jingdao},<br>
            booktitle={2023 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)},<br>
            title={A Bibliometric View of AI Ethics Development},<br>
            year={2023},<br>
            volume={},<br>
            number={},<br>
            pages={1-5},<br>
            doi={10.1109/CSDE59766.2023.10487710},<br>
        }
		</div>
    </li>
    <li>
	Garshabi, A., Wang, J., <b>Chen, J.</b>, and Ma, J. (2023). <br>
	<a target="_blank" href="https://doi.org/10.22260/ICRA2023/0003"><strong>Human-Robot Collaboration in the Construction Industry: A Mini-review</strong></a><br>
	 2023 IEEE International Conference on Robotics and Automation (ICRA) Workshop on Future of Construction, London, U.K., June 2,  <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @inproceedings{garshasbi2023,<br>
            doi = {10.22260/ICRA2023/0003},<br>
            year = 2023,<br>
            month = {July},<br>
            author = {Garshasbi, Ali and Wang, Jun and Chen, Jingdao and Ma, Junfeng},<br>
            title = {Human-Robot Collaboration in the Construction Industry: A Mini-review},<br>
            booktitle = {Proceedings of the 2nd Future of Construction Workshop at the International Conference on Robotics and Automation (ICRA 2023)},<br>
            isbn = {-},<br>
            issn = {2413-5844},<br>
            publisher = {International Association for Automation and Robotics in Construction (IAARC)},<br>
            editor = {Chen, Jingdao (Mississippi State University) and Cho, Yong K. (Georgia Institute of Technology) and Jeong, Inbae (North Dakota State University) and Feng, Chen (New York University) and Zhang, Liangjun (Baidu Research) and Fallon, Maurice (University of Oxford) and Morin, Kristian (HILTI) and Nair, Ashish-Devadas (HILTI)},<br>
            pages = {1-4},<br>
            address = {London, UK},<br>
            }
		</div>
	</li>
    <li>
	<b>Chen, J.</b>, Gugssa, M., Yee, J., Wang, J., Goodin, C., and Ram Das, A. (2023). <br>
	<a target="_blank" href="http://doi.org/10.1117/12.2663632"><strong>Framework for digital twin creation in off-road environments from LiDAR scans</strong></a><br>
	 Proc. SPIE 12529, Synthetic Data for Artificial Intelligence and Machine Learning: Tools, Techniques, and Applications, 125290F (13 June 2023) <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/Off-Road-Digital-Twin">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @inproceedings{chen2023spie,<br>
            author = {Jingdao Chen and Mikias Gugssa and Justin Yee and Jun Wang and Christopher Goodin and Athish Ram Das},<br>
            title = {{Framework for digital twin creation in off-road environments from LiDAR scans}},<br>
            volume = {12529},<br>
            booktitle = {Synthetic Data for Artificial Intelligence and Machine Learning: Tools, Techniques, and Applications},<br>
            editor = {Christopher L. Howell and Kimberly E. Manser and Raghuveer M. Rao},<br>
            organization = {International Society for Optics and Photonics},<br>
            publisher = {SPIE},<br>
            pages = {125290F},<br>
            keywords = {LiDAR, Off-road, Digital twin, Point cloud, Simulator},<br>
            year = {2023},<br>
            doi = {10.1117/12.2663632},<br>
            URL = {https://doi.org/10.1117/12.2663632},<br>
            }
		</div>
	</li>
    <li>
	Yu, J., <b>Chen, J.</b>, Dabbiru, L., and Goodin, C. (2023). <br>
	<a target="_blank" href=" https://doi.org/10.1117/12.2663098"><strong>Analysis of LiDAR configurations on off-road semantic segmentation performance</strong></a><br>
	 Proc. SPIE 12540, Autonomous Systems: Sensors, Processing, and Security for Ground, Air, Sea, and Space Vehicles and Infrastructure 2023, 1254003 (13 June 2023) <br>
		<a class="paperlink" target="_blank" href="https://github.com/jy603/LidarConfig">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @inproceedings{yu2023spie,<br>
            author = {Jinhee Yu and Jingdao Chen and Lalitha Dabbiru and Christopher T. Goodin},<br>
            title = {{Analysis of LiDAR configurations on off-road semantic segmentation performance}},<br>
            volume = {12540},<br>
            booktitle = {Autonomous Systems: Sensors, Processing, and Security for Ground, Air, Sea, and Space Vehicles and Infrastructure 2023},<br>
            editor = {Michael C. Dudzik and Stephen M. Jameson and Theresa J. Axenson},<br>
            organization = {International Society for Optics and Photonics},<br>
            publisher = {SPIE},<br>
            pages = {1254003},<br>
            keywords = {LiDAR , autonomous vehicles, semantic segmentation},<br>
            year = {2023},<br>
            doi = {10.1117/12.2663098},<br>
            URL = {https://doi.org/10.1117/12.2663098},<br>
            }
		</div>
	</li>
    <li>
	Goh, E., Ward, I. R., Vincent, G., Pak, K., <b>Chen, J.</b>, and Wilson, B. (2023). <br>
	<a target="_blank" href="https://doi.org/10.1109/AERO55745.2023.10115598"><strong>Self-supervised Distillation for Computer Vision Onboard Planetary Robots</strong></a><br>
	 IEEE Aerospace Conference, Big Sky, MT, USA, March 4-11 <br>
		<a class="paperlink" target="_blank" href="https://github.com/jpl-clover/weights">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @INPROCEEDINGS{goh2023,<br>
            author={Goh, Edwin and Ward, Isaac R. and Vincent, Grace and Pak, Kai and Chen, Jingdao and Wilson, Brian},<br>
            booktitle={2023 IEEE Aerospace Conference},<br> 
            title={Self-supervised Distillation for Computer Vision Onboard Planetary Robots},<br> 
            year={2023},<br>
            volume={},<br>
            number={},<br>
            pages={1-11},<br>
            doi={10.1109/AERO55745.2023.10115598},<br>
            }
		</div>
	</li>
    <h3>2022</h3>
    <li>
	Ward, I. R., Moore, C., Pak, K., <b>Chen, J.</b>, and Goh, E. (2022). <br>
	<a target="_blank" href="https://doi.org/10.1007/978-3-031-25056-9_12"><strong>Improving Contrastive Learning on Visually Homogeneous Mars Rover Images</strong></a><br>
	 European Conference on Computer Vision (ECCV) Workshop on AI4Space, Tel Aviv, Israel, Oct 23 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @InProceedings{ward2022,<br>
            author="Ward, Isaac Ronald and Moore, Charles and Pak, Kai and Chen, Jingdao and Goh, Edwin",<br>
            editor="Karlinsky, Leonid and Michaeli, Tomer and Nishino, Ko",<br>
            title="Improving Contrastive Learning onVisually Homogeneous Mars Rover Images",<br>
            booktitle="Computer Vision -- ECCV 2022 Workshops",<br>
            year="2023",<br>
            publisher="Springer Nature Switzerland",<br>
            address="Cham",<br>
            pages="170--185",<br>
            isbn="978-3-031-25056-9",<br>
            }
		</div>
	</li>
    <li>
	Vincent, G., Yepremyan, A., <b>Chen, J.</b>, and Goh, E. (2022). <br>
	<a target="_blank" href="https://doi.org/10.1007/978-3-031-25056-9_7"><strong>Mixed-Domain Training Improves Multi-Mission Terrain Segmentation</strong></a><br>
	 European Conference on Computer Vision (ECCV) Workshop on AI4Space, Tel Aviv, Israel, Oct 23 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @InProceedings{vincent2022,<br>
            author="Vincent, Grace and Yepremyan, Alice and Chen, Jingdao and Goh, Edwin",<br>
            editor="Karlinsky, Leonid and Michaeli, Tomer and Nishino, Ko",<br>
            title="Mixed-Domain Training Improves Multi-mission Terrain Segmentation",<br>
            booktitle="Computer Vision -- ECCV 2022 Workshops",<br>
            year="2023",<br>
            publisher="Springer Nature Switzerland",<br>
            address="Cham",<br>
            pages="96--111",<br>
            isbn="978-3-031-25056-9",<br>
            }
		</div>
	</li>
    <li>
	Kim, S., Yajima, Y., Park, J., <b>Chen, J.</b>, and Cho,Y. (2022). <br>
	<a target="_blank" href="https://koreascience.kr/article/CFKO202221543117703.page"><strong>A Hybrid Semantic-Geometric Approach for Clutter-Resistant Floorplan Generation from Building Point Clouds.</strong></a><br>
	 Proceedings of the 9th International Conference on Construction Engineering and Project Management (ICCEPM), Las Vegas, NV, USA, June 20-23 <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/ICCEPM2022Scan2BIM">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @INPROCEEDINGS{kim2022iccepm,<br>
            author={Kim, Seongyong and Yajima, Yosuke and Park, Jisoo and Chen, Jingdao and Cho, Yong},<br>
            booktitle={2022 International Conference on Construction Engineering and Project Management (ICCEPM)},<br>
            title={A Hybrid Semantic-Geometric Approach for Clutter-Resistant Floorplan Generation from Building Point Clouds},<br>
            year={2022},<br>
            pages={792-799},<br>
            }
		</div>
	</li>
    <li>
	Goh, E., <b>Chen, J.</b>, and Wilson, B. (2022). <br>
	<a target="_blank" href="https://doi.org/10.1109/AERO53065.2022.9843245"><strong>Mars Terrain Segmentation with Less Labels.</strong></a><br>
	 IEEE Aerospace Conference, Big Sky, MT, USA, March 5-12 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
            @INPROCEEDINGS{goh2022,<br>
            author={Goh, Edwin and Chen, Jingdao and Wilson, Brian},<br>
            booktitle={2022 IEEE Aerospace Conference (AERO)},<br>
            title={Mars Terrain Segmentation with Less Labels},<br>
            year={2022},<br>
            pages={1-10},<br>
            doi={10.1109/AERO53065.2022.9843245},<br>
            }
		</div>
	</li>
    <h3>2021</h3>
    <li>
	Yajima, Y., Kim, S., <b>Chen, J.</b>, and Cho,Y. (2021). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2021/0048"><strong>Fast Online Incremental Segmentation of 3D Point Clouds from Disaster Sites.</strong></a><br>
	 Proceedings of the 38th International Symposium on Automation and Robotics in Construction (ISARC), Dubai, UAE, November 2-5 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @inproceedings{yajima2021isarc,<br>
            doi = {10.22260/ISARC2021/0048},<br>
            year = 2021,<br>
            month = {November},<br>
            author = {Yajima, Yosuke and Kim, Seongyong and Chen, Jing Dao and Cho, Yong},<br>
            title = {Fast Online Incremental Segmentation of 3D Point Clouds from Disaster Sites},<br>
            booktitle = {Proceedings of the 38th International Symposium on Automation and Robotics in Construction (ISARC)},<br>
            isbn = {978-952-69524-1-3},<br>
            issn = {2413-5844},<br>
            publisher = {International Association for Automation and Robotics in Construction (IAARC)},<br>
            pages = {341-348},<br>
            address = {Dubai, UAE},<br>
            }
		</div>
	</li>
    <li>
	Kahoush, M., Yajima, Y., Kim, S., <b>Chen, J.</b>, Park, J., Kangisser, S., Irizarry, J., and Cho,Y. (2021). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784483893.109"><strong>Analysis of Flight Parameters on UAV Semantic Segmentation Performance for Highway Infrastructure Monitoring.</strong></a><br>
	 Proceedings of the ASCE 2021 International Conference on Computing in Civil Engineering (i3CE), Orlando, FL, USA, September 12-14 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @inproceedings{kahoush2021i3ce,<br>
            author = {Mark Kahoush  and Yosuke Yajima  and Seongyong Kim  and Jingdao Chen  and Jisoo Park  and Steven Kangisser  and Javier Irizarry  and Yong K. Cho },<br>
            title = {Analysis of Flight Parameters on UAV Semantic Segmentation Performance for Highway Infrastructure Monitoring},<br>
            booktitle = {International Conference on Computing in Civil Engineering 2021},<br>
            year = 2021,<br>
            pages = {885-893},<br>
            doi = {10.1061/9780784483893.109},<br>
            URL = {https://ascelibrary.org/doi/abs/10.1061/9780784483893.109},<br>
        }   
		</div>
	</li>
    <li>
	Yajima, Y., Kahoush, M., Kim, S., <b>Chen, J.</b>, Park, J., Kangisser, S., Irizarry, J., and Cho,Y. (2021). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784483893.110"><strong>AI-driven 3D Point Cloud-Based Highway Infrastructure Monitoring System using UAV.</strong></a><br>
	 Proceedings of the ASCE 2021 International Conference on Computing in Civil Engineering (i3CE), Orlando, FL, USA, September 12-14 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @inproceedings{yajima2021i3ce,<br>
            author = {Yosuke Yajima  and Mark Kahoush  and Seongyong Kim  and Jingdao Chen  and Jisoo Park  and Steven Kangisser  and Javier Irizarry  and Yong K. Cho },<br>
            title = {AI-Driven 3D Point Cloud-Based Highway Infrastructure Monitoring System Using UAV},<br>
            booktitle = {International Conference on Computing in Civil Engineering 2021},<br>
            year = 2021,<br>
            pages = {894-901},<br>
            doi = {10.1061/9780784483893.110},<br>
            URL = {https://ascelibrary.org/doi/abs/10.1061/9780784483893.110},<br>
        }
		</div>
	</li>
    <h3>2020</h3>
	<li>
	<b>Chen, J.</b>, Kim, P., Sun, D.I., Han, C.S., Ahn, Y.H., Ueda, J. and Cho, Y. (2020). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2020/0108"><strong>Workspace Modeling: Visualization and Pose Estimation of Teleoperated Construction Equipment from Point Clouds.</strong></a><br>
	 Proceedings of the 37th International Symposium on Automation and Robotics in Construction (ISARC), Kitakyshu, Japan, October 27-28<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2020isarc,<br>
		author={Jingdao Chen and Pileun Kim and Dong-Ik Sun and Chang-Soo Han and Yong-Han Ahn and Jun Ueda and Yong K. Cho},<br>
		booktitle={37th International Symposium on Automation and Robotics in Construction (ISARC)},<br>
		title={Workspace Modeling: Visualization and Pose Estimation of Teleoperated Construction Equipment from Point Clouds},<br>
		year={2020},<br>
		month={October},<br>
        pages={781-788},<br>
		}
		</div>
	</li><li>
	Price, L., <b>Chen, J.</b>, and Cho, Y. (2020). <br>
	<a target="_blank" href="https://doi.org/10.1007/978-3-030-51295-8_66"><strong>Dynamic Crane Workspace Update for Collision Avoidance during Blind Lift Operations.</strong></a><br>
	 Proceedings of the 18th International Conference on Computing in Civil and Building Engineering, ICCCBE, pp. 959-970, So Paulo, Brazil<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @InProceedings{price2020,<br>
        author="Price, Leon C.  and Chen, Jingdao and Cho, Yong K.",<br>
        editor="Toledo Santos, Eduardo and Scheer, Sergio",<br>
        title="Dynamic Crane Workspace Update for Collision Avoidance During Blind Lift Operations",<br>
        booktitle="Proceedings of the 18th International Conference on Computing in Civil and Building Engineering",<br>
        year="2020",<br>
        publisher="Springer International Publishing",<br>
        address="Cham",<br>
        pages="959--970",<br>
        isbn="978-3-030-51295-8",<br>
        }
		</div>
	</li><li>
	<b>Chen, J.</b>, and Cho, Y. (2020). <br>
	<a target="_blank" href="https://doi.org/10.14279/depositonce-9977"><strong>Unsupervised Crack Segmentation from Disaster Site Point Clouds using Point Feature Clustering.</strong></a><br>
	 Proceedings of Workshop of the European Group for Intelligent Computing in Engineering, EG-ICE, pp. 125-133, Berlin, Germany<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
        @inproceedings {chen2020egice,<br>
           author = {Chen, Jingdao and Cho, Yong},<br>
           editor = {Ungureanu, Lucian Constantin AND Hartmann, Timo},<br>
           title = {Unsupervised Crack Segmentation from Disaster Site Point Clouds using Point Feature Clustering},<br>
           booktitle = {EG-ICE 2020 Workshop on Intelligent Computing in Engineering},<br>
           year = {2020},<br>
           publisher = {Universittsverlag der TU Berlin},<br>
           address = {Berlin},<br>
           doi = {10.14279/depositonce-9977},<br>
           url = {http://dx.doi.org/10.14279/depositonce-9977},<br>
           pages = {125-133},<br>
        }
		</div>
	</li><li>
	Park, J., <b>Chen, J.</b>, and Cho Y. (2020). <br>
		<a target="_blank" href="https://doi.org/10.1061/9780784482865.139"><strong>Point Cloud Information Modeling (PCIM): an Innovative Framework for as-is Information Modeling of Construction Sites</strong></a> <br>
		ASCE Construction Research Congress (CRC) 2020, March 9-10, Tempe, AZ. <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{park2020crc,<br>
		author = {Jisoo Park  and Jingdao Chen  and Yong K. Cho },<br>
		title = {Point Cloud Information Modeling (PCIM): an Innovative Framework for as-is Information Modeling of Construction Sites},<br>
		booktitle = {Construction Research Congress 2020},<br>
		year = {2020},<br>
		}
		</div>
	</li>
    <h3>2019</h3>
    <li>
	<b>Chen, J.</b>, and Cho Y. (2019). <br>
		<a target="_blank" href="https://doi.org/10.1680/icsic.64669.225"><strong>Exemplar-based Building Element Retrieval from Point Clouds</strong></a> <br>
		International Conference on Smart Infrastructure and Construction (ICSIC), Churchill College, Cambridge, UK, July 8-9. <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{chen2019icsic,<br>
		author = {Jingdao Chen and Yong Cho},<br>
		title = {Exemplar-Based Building Element Retrieval from Point Clouds},<br>
		booktitle = {International Conference on Smart Infrastructure and Construction 2019 (ICSIC)},<br>
		year = "2019",<br>
		pages = {225-231},<br>
		doi = {10.1680/icsic.64669.225},<br>
		URL = {https://www.icevirtuallibrary.com/doi/abs/10.1680/icsic.64669.225},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b> and Cho, Y. (2019). <br>
	<a target="_blank" href="https://doi.org/10.1109/URAI.2019.8768770"><strong>Detection of Damaged Infrastructure on Disaster Sites using Mobile Robots.</strong></a><br>
	 IEEE 2019 16th International Conference on Ubiquitous Robots (UR), Jeju, Korea, June 24-27 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2019ur,<br>
		author={J. {Chen} and Y. K. {Cho}},<br>
		booktitle={2019 16th International Conference on Ubiquitous Robots (UR)},<br>
		title={Detection of Damaged Infrastructure on Disaster Sites using Mobile Robots},<br>
		year={2019},<br>
		pages={648-653},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b>, Kim, K.N., Cho,Y., Lee, J., Kim, B., Ahn, Y., and Kang, J. (2019). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784482421.069"><strong>Nuclear Power Plant Disaster Site Simulation using Rigid Body Physics.</strong></a><br>
	 Proceedings of the ASCE 2019 International Conference on Computing in Civil Engineering (i3CE), Atlanta, GA, USA, June 17-19, DOI:10.1061/9780784482421.069 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{chen2019i3ce,<br>
		author = {Jingdao Chen  and Kinam Kim  and Yong K. Cho  and Joo Sung Lee  and Byeol Kim  and Yong Han Ahn  and Junsuk Kang },<br>
		title = {Nuclear Power Plant Disaster Site Simulation Using Rigid Body Physics},<br>
		booktitle = {International Conference on Computing in Civil Engineering 2019},<br>
		year={2019},<br>
		pages = {546-552},<br>
		doi = {10.1061/9780784482421.069},<br>
		URL = {https://ascelibrary.org/doi/abs/10.1061/9780784482421.069},<br>
		}
		</div>
	</li><li>
	Kim, K.N., <b>Chen, J.</b>, and Cho, Y. (2019). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784482438.007"><strong>Evaluation of Machine Learning Algorithms for Worker's Motion Recognition using Motion Sensors.</strong></a><br>
	 Proceedings of the ASCE 2019 International Conference on Computing in Civil Engineering (i3CE), Atlanta, GA, USA, June 17-19, DOI:10.1061/9780784482438.007 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{kim2019i3ce,<br>
		author = {Kinam Kim  and Jingdao Chen  and Yong K. Cho },<br>
		title = {Evaluation of Machine Learning Algorithms for Worker's Motion Recognition Using Motion Sensors},<br>
		booktitle = {International Conference on Computing in Civil Engineering 2019},<br>
		year={2019},<br>
		pages = {51-58},<br>
		doi = {10.1061/9780784482438.007},<br>
		URL = {https://ascelibrary.org/doi/abs/10.1061/9780784482438.007},<br>
		}
		</div>
	</li>
    <h3>2018</h3>
    <li>
	<b>Chen, J.</b>, Kim, P., Cho, Y., and Ueda, J. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1109/URAI.2018.8441896"><strong>Object-sensitive potential fields for mobile robot navigation and mapping in indoor environments.</strong></a><br>
	 Proceedings of the 2018 IEEE 15th International Conference on Ubiquitous Robots (UR), Honolulu, HI, USA, June 26-30, 10.1109/URAI.2018.8441896 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2018ur,<br>
		 author={J. {Chen} and P. {Kim} and Y. K. {Cho} and J. {Ueda}}, <br>
		 booktitle={2018 15th International Conference on Ubiquitous Robots (UR)}, <br>
		 title={Object-sensitive potential fields for mobile robot navigation and mapping in indoor environments},<br>
		 year={2018},<br>
		 pages={328-333},<br>
		 doi={10.1109/URAI.2018.8441896},<br>
		 month={June},<br>
		 }
		</div>
	</li><li>
	<b>Chen, J.</b>, Cho, Y., and Ueda, J. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1109/ICRA.2018.8461095"><strong>Sampled-Point Network for Classification of Deformed Building Element Point Clouds.</strong></a><br>
	 Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), BrisBane, Australia, May 21-25, 10.1109/ICRA.2018.8461095 <br>
		<a class="paperlink" target="_blank" href="https://github.com/jingdao/BIMNet10">[code]</a>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2018icra,<br>
		author={J. {Chen} and Y. K. {Cho} and J. {Ueda}},<br>
		booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},<br>
		title={Sampled-Point Network for Classification of Deformed Building Element Point Clouds},<br>
		year={2018},<br>
		pages={2164-2169},<br>
		}
		</div>
	</li><li>
	Fang, Y., <b>Chen, J.</b>, Cho, Y., Zhang, S., and Perez, E. (2018). <br>
	<a target="_blank" href="https://www.researchgate.net/publication/329250361_Enhancing_Blind_Lift_Safety_on_Offshore_Platforms_through_Real-time_Sensing_and_Visualization"><strong> Enhance Blind Lift Safety by Real-Time Sensing and Visualization.</strong></a><br>
	 Proceedings of the 18th International Conference on Construction Applications of Virtual Reality (CONVR2018), Auckland, New Zealand, Nov 22-23 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{fang2018convr,<br>
		author={Yihai Fang and Jingdao Chen and Yong Cho and Sijie Zhang and Esau Perez},<br>
		booktitle={18th International Conference on Construction Applications of Virtual Reality (CONVR)},<br>
		title={Enhance Blind Lift Safety by Real-Time Sensing and Visualization},<br>
		year={2018},<br>
		month={November},<br>
		}
		</div>
	</li><li>
	Kim, P., <b>Chen, J.</b>, Kim, J., and Cho, Y. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1007/978-3-319-91635-4_14"><strong>SLAM-Driven Intelligent Autonomous Mobile Robot Navigation for Construction Applications.</strong></a><br>
	 Proceedings of Workshop of the European Group for Intelligent Computing in Engineering, EG-ICE,. pp. 254-269, Lausanne, Switzerland, DOI: 10.1007/978-3-319-91635-4_14 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@InProceedings{kim2018egice,<br>
		author="Kim, Pileun and Chen, Jingdao and Kim, Jitae and Cho, Yong K.",<br>
		editor="Smith, Ian F. C.  and Domer, Bernd",<br>
		title="SLAM-Driven Intelligent Autonomous Mobile Robot Navigation for Construction Applications",<br>
		booktitle="Advanced Computing Strategies for Engineering",<br>
		year="2018",<br>
		publisher="Springer International Publishing",<br>
		pages="254--269",<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b> and Cho, Y. (2018). <br>
	<a target="_blank" href="https://www.researchgate.net/publication/325813565_Point-to-point_Comparison_Method_for_Automated_Scan-vs-BIM_Deviation_Detection"><strong>Point-to-point Comparison Method for Automated Scan-vs-BIM Deviation Detection.</strong></a><br>
	 Proceedings of 17th International Conference on Computing in Civil and Building Engineering, Tampere, Finland, June 4-7. <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2018icccbe,<br>
		author={Jingdao Chen and Yong Cho},<br>
		booktitle={17th International Conference on Computing in Civil and Building Engineering},<br>
		title={Point-to-point Comparison Method for Automated Scan-vs-BIM Deviation Detection},<br>
		year={2018},<br>
		month={June},<br>
		}
		</div>
	</li><li>
	Kim, P., <b>Chen, J.</b>, Cho, Y. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784481264.015"><strong>Autonomous Mobile Robot Localization and Mapping for Unknown Construction Environments.</strong></a><br>
	 ASCE Construction Research Congress (CRC) 2018, pp.147-156, April 2-4, New Orleans, LA, DOI: 10.1061/9780784481264.015 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{kim2018crc,<br>
		author = {Pileun Kim  and Jingdao Chen  and Yong K. Cho },<br>
		title = {Autonomous Mobile Robot Localization and Mapping for Unknown Construction Environments},<br>
		booktitle = {Construction Research Congress 2018},<br>
		year = {2018},<br>
		pages = {147-156},<br>
		doi = {10.1061/9780784481264.015},<br>
		URL = {https://ascelibrary.org/doi/abs/10.1061/9780784481264.015},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b>, Cho, Y., and Kim, K. (2018). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784481264.022"><strong>Region Proposal Mechanism for Building Element Recognition for Advanced Scan-to-BIM Process.</strong></a><br>
	ASCE Construction Research Congress 2018,April2-4, New Orleans, LA, Doi: 10.1061/9780784481264.022  <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{chen2018crc,<br>
		author = {Jingdao Chen  and Yong K. Cho  and Kyungki Kim },<br>
		title = {Region Proposal Mechanism for Building Element Recognition for Advanced Scan-to-BIM Process},<br>
		booktitle = {Construction Research Congress 2018},<br>
		year = {2018},<br>
		pages = {221-231},<br>
		doi = {10.1061/9780784481264.022},<br>
		URL = {https://ascelibrary.org/doi/abs/10.1061/9780784481264.022},<br>
		}
		</div>
	</li>
    <h3>2017</h3>
    <li>
	Kim, P., <b>Chen, J.</b>, and Cho, Y. (2017). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2017/0122"><strong>Building element recognition with thermal-mapped point clouds.</strong></a><br>
	 Proceedings of the 34th International Symposium on Automation and Robotics in Construction (ISARC), Taipei, Taiwan, June 28-July 1, DOI: 10.22260/ISARC2017/0122 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{kim2017isarc,<br>
		author={Pileun Kim and Jingdao Chen and Yong Cho},<br>
		booktitle={34th International Symposium on Automation and Robotics in Construction (ISARC)},<br>
		title={Building element recognition with thermal-mapped point clouds},<br>
		year={2017},<br>
		month={June},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b>, Fang, Y., and Cho, Y. (2017). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784480830.016"><strong>Mobile Asset Tracking for Dynamic 3D Crane Workspace Generation in Real Time.</strong></a><br>
	 Proceedings of the 2017 International Workshop on Computing for Civil Engineering (IWCCE), Seattle, WA, USA, June 25-27, DOI: 10.1061/9780784480830.016 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{chen2017crane,<br>
		author = {Jingdao Chen  and Yihai Fang  and Yong K. Cho },<br>
		title = {Mobile Asset Tracking for Dynamic 3D Crane Workspace Generation in Real Time},<br>
		booktitle = {International Workshop on Computing in Civil Engineering 2017},<br>
		year = {2017},<br>
		pages = {122-129},<br>
		doi = {10.1061/9780784480830.016},<br>
		URL = {https://ascelibrary.org/doi/abs/10.1061/9780784480830.016},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b>, Fang, Y., and Cho, Y. (2017). <br>
	<a target="_blank" href="https://doi.org/10.1061/9780784480823.005"><strong>Unsupervised Recognition of Volumetric Structural Components from Building Point Clouds.</strong></a><br>
	 Proceedings of the 2017 International Workshop on Computing for Civil Engineering (IWCCE), Seattle, WA, USA, June 25-27, DOI: 10.1061/9780784480823.005 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@inproceedings{chen2017iwcce,<br>
		author = {Jingdao Chen  and Yihai Fang  and Yong K. Cho },<br>
		title = {Unsupervised Recognition of Volumetric Structural Components from Building Point Clouds},<br>
		booktitle = {International Workshop on Computing in Civil Engineering 2017},<br>
		year = {2017},<br>
		pages = {34-42},<br>
		doi = {10.1061/9780784480823.005},<br>
		URL = {https://ascelibrary.org/doi/abs/10.1061/9780784480823.005},<br>
		}
		</div>
	</li>
    <h3>2016</h3>
    <li>
	Kim, P., Cho, Y., and <b>Chen, J.</b> (2016). <br>
	<a target="_blank" href="https://www.researchgate.net/publication/318753269_AUTOMATIC_REGISTRATION_OF_LASER_SCANNED_COLOR_POINT_CLOUDS_BASED_ON_COMMON_FEATURE_EXTRACTION"><strong> Automatic Registration of Laser Scanned Color Point Clouds Based on Common Feature Extraction.</strong></a><br>
	 16th International Conference on Construction Applications of Virtual Reality (CONVR), Hong Kong, Dec. 11-13 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2016convr,<br>
		author={Pileun Kim and Yong Cho and Jingdao Chen},<br>
		booktitle={16th International Conference on Construction Applications of Virtual Reality (CONVR)},<br>
		title={Automatic Registration of Laser Scanned Color Point Clouds Based on Common Feature Extraction},<br>
		year={2016},<br>
		month={December},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b>, Fang, Y., and Cho, Y. (2016). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2016/0027"><strong>Automated Equipment Recognition and Classification from Scattered Point Clouds for Construction Management.</strong></a><br>
	 International Symposium on Automation and Robotics in Construction (ISARC), Auburn, AL, July 18-21, 2016, DOI: 10.22260/ISARC2016/0027 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2016isarc,<br>
		author={Jingdao Chen and Yihai Fang and Yong Cho},<br>
		booktitle={33rd International Symposium on Automation and Robotics in Construction (ISARC)},<br>
		title={Automated Equipment Recognition and Classification from Scattered Point Clouds for Construction Management},<br>
		year={2016},<br>
		month={July},<br>
		}
		</div>
	</li><li>
	<b>Chen, J.</b> and Cho, Y. (2016). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2016/0028"><strong>Real-time 3D Mobile Mapping for the Built Environment</strong></a><br>
	. International Symposium on Automation and Robotics in Construction (ISARC), Auburn, AL, July 18-21, 2016, DOI: 10.22260/ISARC2016/0028 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{chen2016slam,<br>
		author={Jingdao Chen and Yong Cho},<br>
		booktitle={33rd International Symposium on Automation and Robotics in Construction (ISARC)},<br>
		title={Real-time 3D Mobile Mapping for the Built Environment},<br>
		year={2016},<br>
		month={July},<br>
		}
		</div>
	</li><li>
	Fang, Y., <b>Chen, J.</b>, Cho, Y., and Zhang, P. (2016). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2016/0074"><strong>A Point Cloud-Vision Hybrid Approach for 3D Location Tracking of Mobile Construction Assets.</strong></a><br>
	 International Symposium on Automation and Robotics in Construction (ISARC), Auburn, AL, July 18-21, 2016, DOI: 10.22260/ISARC2016/0074 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{fang2016isarc,<br>
		author={Yihai Fang and Jingdao Chen and Yong Cho and Peiyao Zhang},<br>
		booktitle={33rd International Symposium on Automation and Robotics in Construction (ISARC)},<br>
		title={A Point Cloud-Vision Hybrid Approach for 3D Location Tracking of Mobile Construction Assets},<br>
		year={2016},<br>
		month={July},<br>
		}
		</div>
	</li><li>
	Kim, P., Cho, Y. <b>Chen, J.</b> (2016). <br>
	<a target="_blank" href="https://doi.org/10.22260/ISARC2016/0083"><strong>Target-Free Automatic Registration of Point Clouds.</strong></a><br>
	 International Symposium on Automation and Robotics in Construction (ISARC), Auburn, AL, July 18-21, 2016, DOI: 10.22260/ISARC2016/0083 <br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@INPROCEEDINGS{kim2016isarc,<br>
		author={Pileun Kim and Yong Cho and Jingdao},<br>
		booktitle={33rd International Symposium on Automation and Robotics in Construction (ISARC)},<br>
		title={Target-Free Automatic Registration of Point Clouds},<br>
		year={2016},<br>
		month={July},<br>
		}
		</div>
	</li>
												</ol>
									        </div>
									    </div>
									</div>
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingThree">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" target="_blank" href="#collapseThree" aria-expanded="false" aria-controls="collapseThree"> Workshops
									            </a>
									        </h4>
									    </div>
									    <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
									        <div class="panel-body">
												<ol class='publication-list'>
	<h3>2024</h3>
    <li>
	<b>Chen, J.</b>, Cho, Y., Feng, C., Jeong, I., Zhang, L., Fallon, M., Helmberger, M., Morin, K., and Garcia de Soto, B.(2024). <br>
	<a target="_blank" href="https://construction-robots.github.io/"><strong>Future of Construction: Lifelong Learning Robots in Changing Construction Sites</strong></a><br>
    Organizing committee. Workshop at the IEEE Conference on Robotics and Automation (ICRA), May 13, 2024. <br>
    </li>
    <li>
	<b>Chen, J.</b> (2024). <br>
	<a target="_blank" href="https://www.cmu.edu/cee/i3ce2024/workshops-and-posters.html"><strong>Deep Learning Tools for Understanding and Modeling the Built Environment</strong></a><br>
    Presenter. Workshop at the ASCE International Conference on Computing in Civil Engineering (I3CE), July 28, 2024 <br>
    </li>
	<h3>2023</h3>
    <li>
	<b>Chen, J.</b>, Cho, Y., Feng, C., Jeong, I., Zhang, L., Fallon, M., Helmberger, M., Morin, K., and Nair A.(2023). <br>
	<a target="_blank" href="https://construction-robots.github.io/"><strong>Future of Construction: Robot Perception, Mapping, Navigation, Control in Unstructured and Cluttered Environments</strong></a><br>
    Organizing committee. Workshop at the IEEE Conference on Robotics and Automation (ICRA), June 2, 2023. <br>
    </li>
	<h3>2022</h3>
    <li>
	<b>Chen, J.</b> (2022). <br>
	<a target="_blank" href="https://iccepm2022.com/post-conference-workshops/"><strong>Tutorial on Scan-to-BIM using Python and Open3D</strong></a><br>
    Presenter. Workshop at the International Conference on Construction Engineering and Project Management (ICCEPM), June 24, 2022. <br>
    </li>
    <li>
	<b>Chen, J.</b>, Cho, Y., Feng, C., Jeong, I., and Zhang, L. (2022). <br>
	<a target="_blank" href="https://construction-robots.github.io/"><strong>Future of Construction: Build Faster, Better, Safer - Together with Robots</strong></a><br>
    Organizing committee. Workshop at the IEEE Conference on Robotics and Automation (ICRA), May 23, 2022. <br>
    </li>
    <h3>2021</h3>
    <li>
	<b>Chen, J.</b>, Park, J., Yajima, Y., Kim, S. (2021). <br>
	<a target="_blank" href="https://cv4aec.github.io/index.html"><strong>GTS2B</strong></a><br>
    1st Workshop and Challenge on Computer Vision in the Built Environment. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 20, 2021. <br>
    </li>
												</ol>
									        </div>
										</div>
									</div>
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingFour">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" target="_blank" href="#collapseFour" aria-expanded="false" aria-controls="collapseFour"> Book Chapters
									            </a>
									        </h4>
									    </div>
									    <div id="collapseFour" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFour">
									        <div class="panel-body">
												<ol class='publication-list'>
	<h3>2022</h3>
    <li>
	<b>Chen, J.</b>, and Cho, Y. (2022). <br>
	<a target="_blank" href="https://www.e-elgar.com/shop/usd/research-companion-to-building-information-modeling-9781839105517.html"><strong>Rapid scan-to-building information modeling using robotics and artificial intelligence for construction applications</strong></a><br>
	Research Companion to Building Information Modeling, March 2022<br>
		<a class="paperlink" onclick="$(this).siblings('.bibref').slideToggle()">[bibtex]</a>
		<div class="bibref">
		@incollection{chen2022bim,<br>
			title={Rapid scan-to-building information modeling using robotics and artificial intelligence for construction applications},<br>
			author={Chen, J., and Cho, Y.},<br>
			editor={Lu, W. and Anumba, C.J.},<br>
			booktitle={Research Companion to Building Information Modeling},<br>
			isbn={9781839105517},<br>
			series={Elgar Companions to the Built Environment Series},<br>
			url={https://books.google.com/books?id=stqZzgEACAAJ},<br>
			year={2022},<br>
			publisher={Edward Elgar Publishing, Incorporated},<br>
		}  
		</div>
	</li>
												</ol>
									        </div>
										</div>
									</div>
									<div class="panel panel-default">
									    <div class="panel-heading" role="tab" id="headingFive">
									        <h4 class="panel-title">
									            <a class="collapsed" data-toggle="collapse" data-parent="#accordion" target="_blank" href="#collapseFive" aria-expanded="false" aria-controls="collapseFive"> Bibliography
									            </a>
									        </h4>
									    </div>
									    <div id="collapseFive" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFive">
									        <div id="bibliography" class="panel-body" style="font-size:14px;font-family:monospace;">
											</div>
									    </div>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section class="colorlib-experience" data-section="teaching">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 " data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading ">Teaching</h2>
						</div>
					</div>
                    Courses at Mississippi State University:
                    <ul>
						<li> Spring 2025 - CSE 3683: AI Fundamentals </li> 					 	
						<li> Fall 2024 - CSE 4643/6643: AI Robotics </li> 					 	
						<li> Spring 2024 - CSE 4633/6633: Artificial Intelligence </li> 					 	
						<li> Fall 2023 - CSE 4643/6643: AI Robotics </li> 					 	
						<li> Spring 2023 - CSE 4633/6633: Artificial Intelligence </li> 					 	
						<li> Fall 2022 - CSE 4643/6643: AI Robotics </li> 					 	
						<li> Spring 2022 - CSE 8990: Special Topics in CS: Advanced AI Robotics </li>
						<li> Fall 2021 - CSE 4643/6643: AI Robotics </li> 					 	
                    </ul>
                </div>
            </section>

			<section class="colorlib-experience" data-section="join">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 " data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading ">Join</h2>
						</div>
					</div>
                    Students with experience in the areas of robotics, machine learning, artificial intelligence, or computer vision are encouraged to apply.
                    Mississippi State University has fully-online PhD in Computer Science programs available.
                    Please send your latest CV to 
					<a class='external' target="_blank" href="mailto:chenjingdao@cse.msstate.edu" style="color:#2c98f0">chenjingdao@cse.msstate.edu</a>
                    if you are interested in joining our research group.
                </div>
            </section>

			<section class="colorlib-experience" data-section="code">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 " data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading ">Code</h2>
						</div>
					</div>
					<div class="row row-pt-md">
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
									<a class="paperlink" target="_blank" href="https://github.com/jingdao/learn_region_grow"><h3>Learnable Region Growing</h3></a>
									<p>Code to perform class-agnostic 3D point cloud segmentation using a learnable region growing method. Code available in Tensorflow 1 and Tensorflow 2.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jingdao/IR_detection"><h3>Infrared Segmentation</h3></a>
									<p>Code to perform person detection by semantic segmentation from night-time infrared (IR) images. Implemented in Tensorflow.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jingdao/multiview_segmentation"><h3>Multi-view Incremental Segmentation</h3></a>
									<p>Code to incrementally perform semantic instance segmentation of laser-scanned 3D point clouds. Implemented in ROS + Tensorflow.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jingdao/point_cloud_scene_completion"><h3>Point Cloud Scene Completion</h3></a>
									<p>Code to perform scene completion of obstructed building facades using generative adversarial inpainting. Implemented in Tensorflow.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jingdao/Off-Road-Digital-Twin"><h3>Off-Road Digital Twin</h3></a>
									<p>Code to create digital twins of off-road environments, including tree segmentation and terrain modeling.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jy603/LidarConfig"><h3>LiDAR Configuration Analysis</h3></a>
									<p>Code to analyze effect of LiDAR configuration change on semantic segmentation performance. Evaluated on MAVS and RELLIS-3D datasets.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jingdao/ICCEPM2022Scan2BIM"><h3>Scan-to-BIM</h3></a>
									<p>Code to create IFC building models from point cloud data, using Pytorch and Open3D (presented at ICCEPM 2022). Jupyter notebooks and slides available <a target="_blank" href="https://drive.google.com/drive/folders/1fL3MclP7Wj6UUOjAsLdTmyEEi67xqVOZ?usp=sharing">here</a>.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/shaswata09/Offroad-Path-Planning"><h3>URA*: Uncertainty-aware A*</h3></a>
									<p>Code for uncertainty-aware path planning in off-road environments using Python. Jupyter notebooks and datasets available.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jingdao/crack_detection/tree/master"><h3>Crack-Embed</h3></a>
									<p>Learned point cloud embeddings with anomaly detection for crack segmentation. Source code and point cloud data available.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/jy603/LiDAR_Traversability_Estimation"><h3>SSL Traversability</h3></a>
									<p>Code for self-supervised traversability estimation on off-road environments and construction sites.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-5">
								<span class="icon">
                                    <i class="fab fa-fw fa-github"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://github.com/RAPTOR-MSSTATE/WRIVA-Project-Datasets-and-Models"><h3>Image Artifacts Dataset</h3></a>
									<p>Dataset of various types of image artifacts (soil, rain, finger on lens). Example artifact detection scripts available.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-6">
								<span class="icon">
                                    <i class="fab fa-fw fa-python"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="https://drive.google.com/drive/folders/1ZklFdANdE57wgbMi9QBgvOVQDdO1Tng_?usp=sharing"><h3>LiDAR Processing Practice</h3></a>
									<p>Jupyter notebook for practicing LiDAR point cloud processing algorithms such as visualization, ground filtering, filtering by distance, and Euclidean clustering.</p>
								</div>
							</div>
						</div>
						<div class="col-md-4 text-center ">
							<div class="services color-6">
								<span class="icon">
                                    <i class="fab fa-fw fa-python"></i>
								</span>
								<div class="desc">
                                    <a class="paperlink" target="_blank" href="python.html"><h3>Python Coding Exercises</h3></a>
									<p>A series of intro-level Python coding exercises for scientific computing applications. Jupyter notebook available <a target="_blank" href="https://colab.research.google.com/drive/1_smkHj5R0FboaZ-XXV3cGtvcxBez7RX_?usp=sharing">here</a>.</p>
								</div>
							</div>
						</div>
                    </div>
				</div>
			</section>

			<section class="colorlib-experience" data-section="gallery">
				<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-6 col-md-offset-3 col-md-pull-3 " data-animate-effect="fadeInLeft">
							<h2 class="colorlib-heading ">Gallery</h2>
						</div>
					</div>
					<div class="row row-pt-md">
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/summer_camp.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/hanyang.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/thanksgiving.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/icra2023.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/guardian.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/i3ce2024.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/lab_photos.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/graduation.jpg" class="gallery">
                        </div>
						<div class="col-md-4 text-center ">
                            <img src="images/gallery/cavs_quadruped.jpg" class="gallery">
                        </div>
                    </div>
				</div>
			</section>


		</div><!-- end:colorlib-main -->
	</div><!-- end:container-wrap -->
	</div><!-- end:colorlib-page -->

	<!-- jQuery -->
	<script src="js/jquery-3.6.4.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>
	<!-- Owl carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Counters -->
	<script src="js/jquery.countTo.js"></script>
	
	
	<!-- MAIN JS -->
	<script src="js/main.js"></script>

	</body>
</html>

